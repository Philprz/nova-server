import os
import json
import httpx
from typing import Dict, Any, List, Optional
from dotenv import load_dotenv
import logging
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
from datetime import datetime
load_dotenv()
logger = logging.getLogger("llm_extractor")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o")
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
ANTHROPIC_MODEL = os.getenv("ANTHROPIC_MODEL", "claude-3-sonnet-20240229")

class LLMExtractor:
    """
    Classe pour extraire des informations structur√©es √† partir de texte en utilisant Claude
    """
    @retry(
        stop=stop_after_attempt(3),  # R√©essaye Claude 3 fois
        wait=wait_exponential(multiplier=1, min=2, max=10),  # Attends 2s, 4s, 8s
        retry=retry_if_exception_type((httpx.TimeoutException, httpx.RequestError)),
        reraise=True  # Relance si tout foire pour trigger le fallback
    )
    async def _call_claude(self, message: str):
        """Appel primary √† Claude avec prompt syst√®me original."""
        system_prompt = """
Tu es NOVA, un assistant commercial intelligent qui comprend diff√©rents types de demandes.

Analyse la demande utilisateur et d√©termine le TYPE D'ACTION puis extrais les informations :

TYPES D'ACTIONS POSSIBLES :
1. "DEVIS" - G√©n√©ration de devis/proposition commerciale
2. "RECHERCHE_PRODUIT" - Recherche de produits par caract√©ristiques
3. "INFO_CLIENT" - Consultation d'informations client
4. "CONSULTATION_STOCK" - V√©rification de stock
5. "AUTRE" - Autre demande

Pour une demande de DEVIS, extrais :
- Nom du client
- Liste des produits avec codes/r√©f√©rences, noms et quantit√©s
Format JSON requis:
{
"products": [{"code": "CODE_PRODUIT", "name": "NOM_PRODUIT", "quantity": QUANTIT√â}]
}
Pour une RECHERCHE_PRODUIT, extrais :
- Caract√©ristiques recherch√©es (vitesse, type, fonctionnalit√©s...)
- Cat√©gorie de produit (imprimante, ordinateur, etc.)
- Crit√®res sp√©cifiques (recto-verso, r√©seau, laser, etc.)

R√©ponds UNIQUEMENT au format JSON suivant:
{
"action_type": "DEVIS|RECHERCHE_PRODUIT|INFO_CLIENT|CONSULTATION_STOCK|AUTRE",
"client": "NOM_DU_CLIENT (si pertinent)",
"products": [{"code": "CODE_PRODUIT", "quantity": QUANTIT√â}] (pour DEVIS),
"search_criteria": {
"category": "TYPE_PRODUIT",
"characteristics": ["caract√©ristique1", "caract√©ristique2"],
"specifications": {"vitesse": "50 ppm", "type": "laser", "fonctions": ["recto-verso", "r√©seau"]}
} (pour RECHERCHE_PRODUIT),
"query_details": "d√©tails sp√©cifiques de la demande"
}
"""
        user_message = f"Voici la demande de devis √† analyser: {message}"
        headers = {
            "x-api-key": ANTHROPIC_API_KEY,
            "anthropic-version": "2023-06-01",
            "content-type": "application/json"
        }
        payload = {
            "model": ANTHROPIC_MODEL,
            "max_tokens": 1024,
            "system": system_prompt,
            "messages": [{"role": "user", "content": user_message}],
            "temperature": 0.0
        }
        async with httpx.AsyncClient(timeout=httpx.Timeout(15.0)) as client:
            response = await client.post(
                "https://api.anthropic.com/v1/messages",
                headers=headers,
                json=payload
            )
            response.raise_for_status()
            return response.json()

    async def _call_openai(self, message: str):
        """Fallback √† OpenAI."""
        logger.info("üîÑ Switch to OpenAI fallback ‚Äì Claude unavailable")
        # Prompt adapt√© pour OpenAI (copi√© de ton system_prompt Claude, mais en format messages)
        system_prompt = """
Tu es NOVA, un assistant commercial intelligent qui comprend diff√©rents types de demandes.

Analyse la demande utilisateur et d√©termine le TYPE D'ACTION puis extrais les informations :

TYPES D'ACTIONS POSSIBLES :
1. "DEVIS" - G√©n√©ration de devis/proposition commerciale
2. "RECHERCHE_PRODUIT" - Recherche de produits par caract√©ristiques
3. "INFO_CLIENT" - Consultation d'informations client
4. "CONSULTATION_STOCK" - V√©rification de stock
5. "AUTRE" - Autre demande

Pour une demande de DEVIS, extrais :
- Nom du client
- Liste des produits avec codes/r√©f√©rences, noms et quantit√©s
Format JSON requis:
{
"products": [{"code": "CODE_PRODUIT", "name": "NOM_PRODUIT", "quantity": QUANTIT√â}]
}
Pour une RECHERCHE_PRODUIT, extrais :
- Caract√©ristiques recherch√©es (vitesse, type, fonctionnalit√©s...)
- Cat√©gorie de produit (imprimante, ordinateur, etc.)
- Crit√®res sp√©cifiques (recto-verso, r√©seau, laser, etc.)

R√©ponds UNIQUEMENT au format JSON suivant:
{
"action_type": "DEVIS|RECHERCHE_PRODUIT|INFO_CLIENT|CONSULTATION_STOCK|AUTRE",
"client": "NOM_DU_CLIENT (si pertinent)",
"products": [{"code": "CODE_PRODUIT", "quantity": QUANTIT√â}] (pour DEVIS),
"search_criteria": {
"category": "TYPE_PRODUIT",
"characteristics": ["caract√©ristique1", "caract√©ristique2"],
"specifications": {"vitesse": "50 ppm", "type": "laser", "fonctions": ["recto-verso", "r√©seau"]}
} (pour RECHERCHE_PRODUIT),
"query_details": "d√©tails sp√©cifiques de la demande"
}
"""

        user_message = f"Voici la demande de devis √† analyser: {message}"

        async with httpx.AsyncClient(timeout=httpx.Timeout(15.0)) as client:
            response = await client.post(
                "https://api.openai.com/v1/chat/completions",
                json={
                    "model": OPENAI_MODEL,
                    "messages": [
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_message}
                    ],
                    "max_tokens": 1000,
                    "temperature": 0.0
                },
                headers={"Authorization": f"Bearer {OPENAI_API_KEY}", "Content-Type": "application/json"}
            )
            response.raise_for_status()
            return response.json()["choices"][0]["message"]["content"]

    async def extract_quote_info(self, prompt: str) -> Dict[str, Any]:
        logger.error(f"üö® FONCTION extract_quote_info APPEL√âE AVEC: {prompt}")
        logger.info(f"Extraction d'informations de devis √† partir de: {prompt}")

        try:
            response_data = await self._call_claude(prompt)
            claude_content = response_data.get("content", [{}])[0].get("text", "")
            logger.info(f"CONTENU CLAUDE EXTRAIT: {claude_content}")
            start_idx = claude_content.find("{")
            end_idx = claude_content.rfind("}") + 1
            if start_idx >= 0 and end_idx > start_idx:
                json_str = claude_content[start_idx:end_idx]
                logger.info(f"üîß JSON EXTRAIT: {json_str}")
                extracted_data = json.loads(json_str)
                logger.info(f"EXTRACTION R√âUSSIE: {extracted_data}")
                action_type = extracted_data.get("action_type", "NON_D√âTECT√â")
                logger.info(f"TYPE D'ACTION D√âTECT√â: {action_type}")
                if action_type == "RECHERCHE_PRODUIT":
                    search_criteria = extracted_data.get('search_criteria', {})
                    logger.info(f"üîç CRIT√àRES DE RECHERCHE: {search_criteria}")
                elif action_type == "DEVIS":
                    client = extracted_data.get('client', 'Non sp√©cifi√©')
                    products = extracted_data.get('products', [])
                    logger.info(f"CLIENT DEVIS: {client}")
                    logger.info(f"PRODUITS DEVIS: {products}")
                return extracted_data
            else:
                logger.error("Impossible de trouver du JSON dans la r√©ponse Claude")
                return {"error": "Format de r√©ponse invalide - pas de JSON trouv√©"}
        except Exception as e:
            logger.error(f"‚ùå Claude failed after retries: {str(e)} ‚Äì Falling back to OpenAI")
            if not OPENAI_API_KEY:
                raise ValueError("OPENAI_API_KEY not set ‚Äì Cannot fallback")
            openai_response = await self._call_openai(prompt)
            try:
                return json.loads(openai_response)
            except json.JSONDecodeError:
                logger.error("‚ùå OpenAI response not valid JSON")
                raise
    async def extract_product_search_criteria(self, product_name: str) -> Dict[str, Any]:
        """Extrait crit√®res de recherche intelligents pour un produit"""
        
        system_prompt = """
    Tu es un assistant sp√©cialis√© dans l'identification de produits bureautiques.
    Analyse le nom de produit et extrais les crit√®res de recherche SAP appropri√©s.

    Pour "Imprimante 49 ppm", extrais:
    - Cat√©gorie: "Imprimante" 
    - Crit√®res: ["laser", "49 ppm", "bureau"]
    - Mots-cl√©s alternatifs: ["50 ppm", "48 ppm"] (proches)

    Format JSON:
    {
    "category": "TYPE_PRODUIT",
    "main_keywords": ["mot1", "mot2"],
    "technical_specs": {"vitesse": "49 ppm", "type": "laser"},
    "alternative_keywords": ["alternatives proches"]
    }
    """
        
        user_message = f"Analyse ce produit: {product_name}"
        
        try:
            response = await self._call_claude_with_system(system_prompt, user_message)
            return json.loads(response)
        except Exception as e:
            logger.error(f"Erreur extraction crit√®res: {e}")
            return {"category": product_name, "main_keywords": [product_name]}
    def _extract_json_from_response(self, content: str) -> Dict[str, Any]:
        """Extrait et parse le JSON de la r√©ponse LLM."""
        start_idx = content.find("{")
        end_idx = content.rfind("}") + 1
        if start_idx >= 0 and end_idx > start_idx:
            json_str = content[start_idx:end_idx]
            try:
                return json.loads(json_str)
            except json.JSONDecodeError as e:
                logger.error(f"‚ùå Erreur parsing JSON: {str(e)}")
                return None
        else:
            logger.error("Impossible de trouver du JSON dans la r√©ponse")
            return None

    async def extract_client_info_from_text(self, user_text: str) -> Dict[str, Any]:
        try:
            system_prompt = """
    Tu es NOVA, un assistant sp√©cialis√© dans l'extraction d'informations client.

    Analyse le texte utilisateur et extrait UNIQUEMENT les informations client disponibles.

    INFORMATIONS √Ä RECHERCHER :
    - Nom de l'entreprise/soci√©t√©
    - Nom de la personne de contact
    - Ville/localisation  
    - SIRET (si mentionn√©)
    - Email de contact
    - T√©l√©phone de contact
    - Adresse compl√®te (si disponible)

    R√©ponds UNIQUEMENT au format JSON suivant:
    {
    "success": true/false,
    "client_data": {
    "company_name": "NOM_ENTREPRISE",
    "contact_name": "NOM_CONTACT", 
    "city": "VILLE",
    "siret": "SIRET_SI_FOURNI",
    "email": "EMAIL_SI_FOURNI",
    "phone": "TELEPHONE_SI_FOURNI",
    "address": "ADRESSE_SI_FOURNIE"
    },
    "confidence": 0-100,
    "missing_fields": ["champs_manquants"]
    }

    Si aucune information client n'est d√©tectable, success = false.
    """
            user_message = f"Texte √† analyser pour extraction client: {user_text}"
            response = await self._call_claude(user_message)
            if response and isinstance(response, dict) and "content" in response:
                content = response.get("content", [{}])[0].get("text", "")
                extracted_json = self._extract_json_from_response(content)
                if extracted_json:
                    logger.info(f"‚úÖ Extraction client r√©ussie: {extracted_json}")
                    return extracted_json
                else:
                    logger.warning("‚ö†Ô∏è JSON non valide dans la r√©ponse Claude")
                    return {"success": False, "error": "Format de r√©ponse invalide"}
            else:
                return {"success": False, "error": "Erreur communication LLM"}
        except Exception as e:
            logger.error(f"‚ùå Erreur extraction client: {e}")
            return {"success": False, "error": str(e)}


    async def extract_quote_request(self, text_input: str) -> Dict[str, Any]:
        """
        M√©thode de compatibilit√© - utilise extract_quote_info en interne
        Correction pour l'erreur AttributeError 'extract_quote_request'
        """
        try:
            logger.info("extract_quote_request appel√©e, redirection vers extract_quote_info")
            result = await self.extract_quote_info(text_input)
            
            # Adapter le format si n√©cessaire pour compatibilit√©
            return {
                "success": True if "error" not in result else False,
                "timestamp": datetime.now().isoformat(),
                "extraction_type": "quote_request",
                "raw_input": text_input,
                "extracted_info": result,
                "confidence_score": 85.0,  # Score par d√©faut
                "extraction_notes": ["Extraction via LLM r√©ussie"]
            }
        except Exception as e:
            logger.error(f"Erreur extract_quote_request: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "extraction_type": "quote_request",
                "timestamp": datetime.now().isoformat()
            }

    async def extract_customer_data(self, text_input: str) -> Dict[str, Any]:
        """
        Extrait sp√©cifiquement les donn√©es client
        Correction pour les erreurs de m√©thodes manquantes
        """
        try:
            logger.info("Extraction de donn√©es client d√©marr√©e")
            result = await self.extract_client_info_from_text(text_input)
            
            return {
                "success": result.get("success", False),
                "extraction_type": "customer_data",
                "customer_info": result.get("client_data", {}),
                "confidence_score": result.get("confidence", 0),
                "missing_fields": result.get("missing_fields", []),
                "timestamp": datetime.now().isoformat()
            }
        except Exception as e:
            logger.error(f"Erreur extraction donn√©es client: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "extraction_type": "customer_data"
            }

    def get_supported_extractions(self) -> List[str]:
        """Retourne la liste des types d'extraction support√©s"""
        return [
            "quote_request",
            "customer_data", 
            "product_search",
            "contact_info",
            "stock_inquiry"
        ]

    async def extract_product_search(self, text_input: str) -> Dict[str, Any]:
        """
        Extrait les crit√®res de recherche de produits
        """
        try:
            logger.info("Extraction de crit√®res de recherche produit")
            result = await self.extract_quote_info(text_input)
            
            if result.get("action_type") == "RECHERCHE_PRODUIT":
                return {
                    "success": True,
                    "extraction_type": "product_search",
                    "search_criteria": result.get("search_criteria", {}),
                    "query_details": result.get("query_details", ""),
                    "timestamp": datetime.now().isoformat()
                }
            else:
                return {
                    "success": False,
                    "error": "Pas de crit√®res de recherche produit d√©tect√©s",
                    "extraction_type": "product_search"
                }
        except Exception as e:
            logger.error(f"Erreur extraction recherche produit: {str(e)}")
            return {
                "success": False,
                "error": str(e),
                "extraction_type": "product_search"
            }

# ====
# FACTORY PATTERN ET INSTANCE GLOBALE  
# ====

# Instance globale de l'extracteur
_llm_extractor: Optional['LLMExtractor'] = None

def get_llm_extractor() -> LLMExtractor:
    """
    Factory pattern pour obtenir l'instance de l'extracteur LLM
    Singleton pattern pour √©viter les connexions multiples
    """
    global _llm_extractor
    if _llm_extractor is None:
        _llm_extractor = LLMExtractor()
        logger.info("Nouvelle instance LLMExtractor cr√©√©e")
    return _llm_extractor

